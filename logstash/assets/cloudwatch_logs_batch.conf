input {
  cloudwatch_logs {
    log_group => [ "/aws/batch/job" ]
    type => "batch"
  }
}

filter {
  if [type] == "batch" {

    if "RequestId" in [message] { drop {} }

    mutate { add_field => { "original_message" => "%{message}"} }

    mutate { gsub => [ "message", "\u001b", "" ] }
    mutate { gsub => [ "message", "[\n\r]", " " ] }

    grok { match => [ "[cloudwatch_logs][log_stream]", "%{DATA:[batch][job]}/%{DATA:priority}/%{UUID:[batch][job_id]}" ] }
    grok { match => [ "[batch][job]", "%{DATA:[blackfynn][environment_name]}-%{DATA:[blackfynn][service_name]}-%{GREEDYDATA:[blackfynn][tier]}-%{DATA}-%{DATA}" ] }

    json { source => "message" }

    # The json filter removes any field it doesn't create so we recreate them here
    if "_jsonparsefailure" not in [tags] {
      grok {
        match => [ "[batch][job]", "%{DATA:[blackfynn][environment_name]}-%{DATA:[blackfynn][service_name]}-%{GREEDYDATA:[blackfynn][tier]}-%{DATA}-%{DATA}" ]
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["ops-elk-data-use100.blackfynn.io:9200","ops-elk-data-use101.blackfynn.io:9200","ops-elk-data-use102.blackfynn.io:9200"]
    document_id => "%{[@metadata][fingerprint]}"
  }
}
